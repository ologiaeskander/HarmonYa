# -*- coding: utf-8 -*-
"""True Hybrid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tA2PMFr0d1XqXBB-1vNL6R5VI3IiyhVC

Imports
"""

import os
import pickle
import numpy as np
import pandas as pd
import random
import tensorflow as tf
from tensorflow import keras
from keras import layers, ops
from keras.saving import register_keras_serializable
from scipy.sparse import load_npz
from sklearn.model_selection import train_test_split

"""Connect Drive"""

#mount drive
from google.colab import drive
drive.mount('/content/drive')

"""# 1. Load Data and Mappings"""

def load_data_and_mappings(data_dir = '/content/drive/MyDrive/Graduation Project/Dev/'):
    """Load sparse matrix and mappings"""
    return {
        'sparse_matrix': load_npz(f'{data_dir}/playlist_track_sparse_matrix.npz'),
        'audio_features': pd.read_csv(f'{data_dir}/combined_audio_features.csv'),
        'track_uri_to_index': pickle.load(open(f'{data_dir}/track_uri_to_index.pkl', 'rb')),
        'track_index_to_uri': pickle.load(open(f'{data_dir}/track_index_to_uri.pkl', 'rb')),
        'playlist_id_to_index': pickle.load(open(f'{data_dir}/playlist_id_to_index.pkl', 'rb')),
        'playlist_index_to_id': pickle.load(open(f'{data_dir}/playlist_index_to_id.pkl', 'rb'))
    }

"""# 2. Data Preparation"""

def prepare_feature_matrix(data):
    """Handle feature matrix creation with missing value imputation"""
    audio_features = data['audio_features']
    feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode',
                   'speechiness', 'acousticness', 'instrumentalness',
                   'liveness', 'valence', 'tempo', 'duration_ms']

    # Create feature matrix with NaNs
    feature_matrix = np.full((len(data['track_index_to_uri']), len(feature_cols)), np.nan)
    for idx, uri in data['track_index_to_uri'].items():
        if uri in audio_features['track_id'].values:
            row = audio_features.loc[audio_features['track_id'] == uri, feature_cols].values[0]
            feature_matrix[idx] = row

    # Impute missing values
    available_data = feature_matrix[~np.isnan(feature_matrix).any(axis=1)]
    mean_features = np.nanmean(feature_matrix, axis=0)
    nan_mask = np.isnan(feature_matrix)
    feature_matrix[nan_mask] = np.take(mean_features, np.where(nan_mask)[1])

    # Normalize
    std_features = np.std(available_data, axis=0)
    return (feature_matrix - mean_features) / (std_features + 1e-8)

def prepare_training_data(sparse_matrix, neg_samples=1):
    """Convert sparse matrix to training data with negative sampling"""
    coo = sparse_matrix.tocoo()

    # Positive samples
    positive_samples = list(zip(coo.row, coo.col, [1]*len(coo.row)))

    # Negative samples - fixed list comprehension
    negative_samples = []
    positive_pairs = set(zip(coo.row, coo.col))
    all_tracks = range(sparse_matrix.shape[1])

    for p, _ in positive_pairs:
        for _ in range(neg_samples):
            t = random.choice(all_tracks)
            while (p, t) in positive_pairs:
                t = random.choice(all_tracks)
            negative_samples.append((p, t, 0))

    # Combine and shuffle
    all_samples = positive_samples + negative_samples
    random.shuffle(all_samples)

    return pd.DataFrame(all_samples, columns=["playlist", "track", "value"])

#load data
data = load_data_and_mappings('/content/drive/MyDrive/Graduation Project/Dev')
# Load audio features from the data dict
audio_features = data['audio_features']
feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode',
               'speechiness', 'acousticness', 'instrumentalness',
               'liveness', 'valence', 'tempo', 'duration_ms']

# Create feature matrix with NaNs
feature_matrix = np.full((len(data['track_index_to_uri']), len(feature_cols)), np.nan)
for idx, uri in data['track_index_to_uri'].items():
    if uri in audio_features['track_id'].values:  # Match full URI
        row = audio_features.loc[audio_features['track_id'] == uri, feature_cols].values[0]
        feature_matrix[idx] = row

# Impute missing values with mean of available features
available_data = feature_matrix[~np.isnan(feature_matrix).any(axis=1)]
mean_features = np.nanmean(feature_matrix, axis=0)
nan_mask = np.isnan(feature_matrix)
feature_matrix[nan_mask] = np.take(mean_features, np.where(nan_mask)[1])

# Normalize using mean and std of AVAILABLE data
std_features = np.std(available_data, axis=0)
feature_matrix = (feature_matrix - mean_features) / (std_features + 1e-8)  # Avoid division by zero

"""# 3. Hybrid Model Architecture"""

@tf.keras.utils.register_keras_serializable()
class HybridRecommender(keras.Model):
    def __init__(self, num_playlists, num_tracks, embedding_size=32, **kwargs):
        super().__init__(**kwargs)
        self.num_playlists = num_playlists
        self.num_tracks = num_tracks
        self.embedding_size = embedding_size

        # Embeddings
        self.pl_embed = layers.Embedding(num_playlists, embedding_size)
        self.tr_embed = layers.Embedding(num_tracks, embedding_size)

        # Feature processing
        self.feat_proj = keras.Sequential([
            layers.Dense(embedding_size, activation='relu'),
            layers.LayerNormalization(),
            layers.Dense(embedding_size)
        ])
        self.feat_gate = layers.Dense(embedding_size, activation='sigmoid')
        self.combine = layers.Dense(embedding_size, activation='tanh')

        # Regularization
        self.dropout = layers.Dropout(0.3)

    def call(self, inputs, training=None):
        pl_idx, tr_idx = inputs[:, 0], inputs[:, 1]

        # Get embeddings
        pl_emb = self.pl_embed(pl_idx)
        tr_emb = self.tr_embed(tr_idx)

        # Get and process features
        features = tf.gather(self.feature_matrix, tr_idx)
        if training:
            features = self.dropout(features)

        feat_proj = self.feat_proj(features)
        feat_proj = feat_proj * self.feat_gate(feat_proj)
        tr_emb = self.combine(tr_emb + feat_proj)

        if training:
            pl_emb = self.dropout(pl_emb)
            tr_emb = self.dropout(tr_emb)

        logits = tf.reduce_sum(pl_emb * tr_emb, axis=1) / 0.2
        return ops.sigmoid(logits)

    def set_feature_matrix(self, feature_matrix):
        """Set the precomputed feature matrix"""
        self.feature_matrix = feature_matrix

"""# 4. Model Training"""

def train_hybrid_model(x_train, y_train, x_val, y_val, num_playlists, num_tracks, feature_matrix):
    """Train and evaluate the hybrid model"""
    model = HybridRecommender(num_playlists, num_tracks)
    model.set_feature_matrix(feature_matrix)

    model.compile(
        optimizer=keras.optimizers.Adam(0.001),
        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.1),
        metrics=[keras.metrics.AUC(name='auc')]
    )

    history = model.fit(
        x_train, y_train,
        batch_size=1024,
        epochs=20,
        validation_data=(x_val, y_val),
        callbacks=[
            keras.callbacks.EarlyStopping(
                monitor='val_auc',
                patience=5,
                mode='max',
                restore_best_weights=True
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=2
            )
        ]
    )
    return model, history

"""# 5. Main Execution"""

if __name__ == "__main__":
    # Load data
    data = load_data_and_mappings('/content/drive/MyDrive/Graduation Project/Dev')

    # Prepare training data
    df = prepare_training_data(data['sparse_matrix'])
    x = df[["playlist", "track"]].values
    y = df["value"].values
    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1)

    # Load audio features
    audio_features = pd.read_csv('/content/drive/MyDrive/Graduation Project/Dev/tracks_features.csv')
    feature_cols = ['danceability', 'energy', 'key', 'loudness', 'mode',
                   'speechiness', 'acousticness', 'instrumentalness',
                   'liveness', 'valence', 'tempo', 'duration_ms']

    # Create feature matrix
    feature_matrix = np.zeros((len(data['track_index_to_uri']), len(feature_cols)))
    for idx, uri in data['track_index_to_uri'].items():
        track_id = uri.split(':')[-1]
        if track_id in audio_features['id'].values:
            feature_matrix[idx] = audio_features.loc[audio_features['id'] == track_id, feature_cols].values[0]

    # Normalize features
    feature_matrix = (feature_matrix - np.mean(feature_matrix, axis=0)) / np.std(feature_matrix, axis=0)

    # Train model
    model, history = train_hybrid_model(
        x_train, y_train, x_val, y_val,
        data['sparse_matrix'].shape[0],
        data['sparse_matrix'].shape[1],
        feature_matrix
    )
    # Save model
    model.save('/content/drive/MyDrive/Graduation Project/Dev/hybrid_recommender.keras')

"""For prediction:

# Load saved model
model = keras.models.load_model('hybrid_recommender.keras')

# Get recommendations
def recommend(playlist_id, top_k=10):
    playlist_idx = playlist_id_to_index[playlist_id]
    all_tracks = np.arange(len(track_index_to_uri))
    pairs = np.array([[playlist_idx, t] for t in all_tracks])
    preds = model.predict(pairs).flatten()
    top_indices = np.argsort(preds)[-top_k:][::-1]
    return [track_index_to_uri[i] for i in top_indices]
"""