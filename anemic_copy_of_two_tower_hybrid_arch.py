# -*- coding: utf-8 -*-
"""Another copy of Two Tower Hybrid Arch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pWDByogm6NgfllqFtVofVgn-iAd0KsfB

# 1. Imports and Setup
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, ops
from keras.saving import register_keras_serializable
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, f1_score
from typing import List, Dict, Tuple, Optional
import pickle
from pathlib import Path
from collections import defaultdict
from scipy.sparse import load_npz
import json
from tensorflow.python.framework.errors_impl import InvalidArgumentError
from scipy.sparse import load_npz
import time

# Install Annoy if needed
try:
    import annoy
except ImportError:
    print("Installing Annoy...")
    !pip install annoy
    import annoy
from annoy import AnnoyIndex

# Try to import tqdm and install it if necessary
try:
    from tqdm import tqdm
except ImportError:
    print("Installing tqdm...")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Path configurations
base_path = Path('/content/drive/MyDrive/Graduation Project/Dev')

"""Load the test dataset"""

def load_test_playlists(json_path: Path) -> List[Dict]:
    """Load test playlists from JSON file"""
    with open(json_path, 'r') as f:
        data = json.load(f)
    return data['playlists']

"""# 2. CUSTOM CLASSES

Binary F1 Score (from the Collaborative Filtering Model)
"""

@tf.keras.utils.register_keras_serializable()
class BinaryF1Score(keras.metrics.Metric):
    """Custom F1 Score metric for model evaluation"""
    def __init__(self, name='f1_score', threshold=0.5, **kwargs):
        super().__init__(name=name, **kwargs)
        self.threshold = threshold
        self.precision = keras.metrics.Precision(thresholds=threshold)
        self.recall = keras.metrics.Recall(thresholds=threshold)

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.cast(y_pred >= self.threshold, tf.float32)
        self.precision.update_state(y_true, y_pred, sample_weight)
        self.recall.update_state(y_true, y_pred, sample_weight)

    def result(self):
        p = self.precision.result()
        r = self.recall.result()
        return 2 * ((p * r) / (p + r + 1e-6))

    def reset_state(self):
        self.precision.reset_state()
        self.recall.reset_state()

"""Balanced Playlist Model (Collaborative Filtering)"""

@tf.keras.utils.register_keras_serializable()
class BalancedPlaylistModel(keras.Model):
    """Custom collaborative filtering model architecture"""
    def __init__(self, num_playlists, num_tracks, embedding_size, **kwargs):
        super().__init__(**kwargs)
        self.num_playlists = num_playlists
        self.num_tracks = num_tracks
        self.embedding_size = embedding_size

        # Gated embeddings with residual connection
        self.track_gate = layers.Dense(embedding_size, activation='sigmoid', name="track_gating")
        self.playlist_gate = layers.Dense(embedding_size, activation='sigmoid', name="playlist_gating")


        self.playlist_embedding = layers.Embedding(
            num_playlists,
            embedding_size,
            name="playlist_embedding",
            embeddings_regularizer=keras.regularizers.l1_l2(l1=1e-8, l2=1e-8))

        self.track_embedding = layers.Embedding(
            num_tracks,
            embedding_size,
            name="track_embedding",
            embeddings_regularizer=keras.regularizers.l1_l2(l1=1e-8, l2=1e-8))

        # Dynamic dropout
        self.dropout = layers.Dropout(0.3, noise_shape=(None, 1))

    def call(self, inputs, training=None):
        pl_idx, tr_idx = inputs[:,0], inputs[:,1]
        pl_emb = self.playlist_embedding(pl_idx)
        tr_emb = self.track_embedding(tr_idx)

        # Gating mechanism
        pl_emb = pl_emb * self.playlist_gate(pl_emb)
        tr_emb = tr_emb * self.track_gate(tr_emb)

        if training:
            pl_emb = self.dropout(pl_emb, training=True)
            tr_emb = self.dropout(tr_emb, training=True)
            self.dropout.rate = min(0.7, self.dropout.rate + 0.02)

        logits = tf.reduce_sum(pl_emb * tr_emb, axis=1) / 0.2
        return ops.sigmoid(logits)

"""# 3. HELPER FUNCTIONS

Playlist Encoder to prepare data for Collaborative Filtering Model
"""

class PlaylistEncoder:
    def __init__(self, track_uri_to_index, playlist_id_to_index, collab_model):
        """Initialize encoder with proper parameters"""
        self.track_uri_to_index = track_uri_to_index
        self.playlist_id_to_index = playlist_id_to_index
        self.collab_model = collab_model
        self.track_emb_layer = collab_model.get_layer("track_embedding")
        self.gate_layer = collab_model.get_layer("track_gating")

    def encode_new_playlist(self, track_uris: List[str]) -> Tuple[List[int], np.ndarray]:
        """Encode a playlist from track URIs"""
        track_indices = [
            self.track_uri_to_index[uri]
            for uri in track_uris
            if uri in self.track_uri_to_index
        ]

        if not track_indices:
            return [], np.zeros((1, self.track_emb_layer.output_dim))

        track_embeddings = self.track_emb_layer(np.array(track_indices))
        gate_weights = self.gate_layer(track_embeddings)
        gated_tracks = track_embeddings * gate_weights
        playlist_embedding = tf.reduce_mean(gated_tracks, axis=0, keepdims=True)
        return track_indices, playlist_embedding.numpy()

"""Load and Preprocess (from the Content based Filtering Model)"""

def load_and_preprocess(data_path: Path) -> Tuple[pd.DataFrame, np.ndarray, List[str]]:
    """Load and preprocess audio features data"""
    df = pd.read_csv(data_path)
    audio_features = [
        'danceability', 'energy', 'key', 'loudness', 'mode',
        'speechiness', 'acousticness', 'instrumentalness',
        'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature'
    ]

    df = df.dropna(subset=audio_features).copy()
    df = df.reset_index(drop=True)

    scaler = StandardScaler()
    features = scaler.fit_transform(df[audio_features])

    if 'id' not in df.columns:
        df['id'] = df.index.astype(str)

    return df, features, audio_features

"""Load both models and necessary mappings"""

def load_models() -> Dict:
    """Load both models and necessary mappings"""
    # Load Collaborative Filtering model
    collab_model = keras.models.load_model(
        base_path / 'Collaborative_Filtering.keras',
        custom_objects={
            'BinaryF1Score': BinaryF1Score,
            'BalancedPlaylistModel': BalancedPlaylistModel
        }
    )

    # Load mappings
    with open(base_path / 'track_uri_to_index.pkl', 'rb') as f:
        track_uri_to_index = pickle.load(f)
    with open(base_path / 'track_index_to_uri.pkl', 'rb') as f:
        track_index_to_uri = pickle.load(f)
    with open(base_path / 'playlist_id_to_index.pkl', 'rb') as f:
        playlist_id_to_index = pickle.load(f)
    with open(base_path / 'playlist_index_to_id.pkl', 'rb') as f:
        playlist_index_to_id = pickle.load(f)

    # Load Content-Based model
    content_index = AnnoyIndex(13, 'angular')
    content_index.load(str(base_path / 'Content_Filtering.ann'))

    # Load content data
    content_df, _, _ = load_and_preprocess(base_path / 'tracks_features.csv')

    # Load sparse matrix
    sparse_matrix = load_npz(base_path / 'playlist_track_sparse_matrix.npz')

    return {
        'collab_model': collab_model,
        'content_index': content_index,
        'content_df': content_df,
        'track_uri_to_index': track_uri_to_index,
        'track_index_to_uri': track_index_to_uri,
        'playlist_id_to_index': playlist_id_to_index,
        'playlist_index_to_id': playlist_index_to_id,
        'sparse_matrix': sparse_matrix
    }

"""# 4. HYBRID RECOMMENDER CLASS"""

class HybridRecommender:
    def __init__(self, models: Dict):
        """Initialize with all required components"""
        self.models = models
        self.collab_model = models["collab_model"]
        self.content_index = models["content_index"]
        self.content_df = models["content_df"]
        self.track_uri_to_index = models["track_uri_to_index"]
        self.track_index_to_uri = models["track_index_to_uri"]

        # Initialize encoder with empty playlist mapping
        self.encoder = PlaylistEncoder(
            track_uri_to_index=self.track_uri_to_index,
            playlist_id_to_index={},  # Empty dict since we don't use playlist IDs
            collab_model=self.collab_model
        )

    def hybrid_recommend(self, track_uris: List[str], top_k: int = 20) -> List[str]:
        """Main recommendation interface"""
        # Filter to known tracks
        known_tracks = [t for t in track_uris if t in self.track_uri_to_index]

        # Dynamic weight based on known tracks
        collab_weight = min(0.7, len(known_tracks) / 15)

        # Collaborative recommendations
        collab_recs = []
        if known_tracks and collab_weight > 0:
            try:
                _, pl_embedding = self.encoder.encode_new_playlist(known_tracks)
                collab_recs = self._find_similar_in_collab_space(pl_embedding, top_k*3)
            except Exception as e:
                print(f"CF failed: {str(e)}")

        # Content-based recommendations
        content_recs = self.get_content_recommendations(track_uris, top_k*3)

        # Combine results
        if collab_recs and content_recs:
            return self._combine_recommendations(collab_recs, content_recs, collab_weight)[:top_k]
        return (collab_recs or content_recs)[:top_k]

    def get_content_recommendations(self, track_uris: List[str], top_k: int) -> List[str]:
        """Content-based recommendations"""
        known_indices = []
        for uri in track_uris:
            matches = self.content_df[self.content_df['id'] == uri]
            if not matches.empty:
                known_indices.append(matches.index[0])

        if not known_indices:
            return []

        candidate_scores = defaultdict(float)
        for idx in known_indices:
            neighbors, dists = self.content_index.get_nns_by_item(idx, 50, include_distances=True)
            for n, d in zip(neighbors, dists):
                candidate_scores[n] += 1 - (d**2)/2

        top_indices = sorted(candidate_scores.keys(), key=lambda x: -candidate_scores[x])[:top_k]
        return [self.content_df.iloc[i]['id'] for i in top_indices]

    def _find_similar_in_collab_space(self, embedding: np.ndarray, top_k: int) -> List[str]:
        """Find similar tracks in collaborative space"""
        weights = self.collab_model.get_layer("track_embedding").weights[0].numpy()
        sims = np.dot(weights, embedding.T).flatten()
        top_indices = np.argsort(sims)[-top_k:][::-1]
        return [self.track_index_to_uri[i] for i in top_indices if i in self.track_index_to_uri]

    def _combine_recommendations(self, collab: List[str], content: List[str], weight: float) -> List[str]:
        """Combine recommendations with weighted scoring"""
        collab_scores = {uri: weight*(0.95**i) for i, uri in enumerate(collab)}
        content_scores = {uri: (1-weight)*(0.95**i) for i, uri in enumerate(content)}
        combined = {uri: collab_scores.get(uri,0)+content_scores.get(uri,0) for uri in set(collab+content)}
        return sorted(combined.keys(), key=lambda x: -combined[x])

"""# 5. DEMONSTRATION AND EVALUATION"""

def evaluate_recommender(recommender: HybridRecommender, test_playlists: List[Dict]) -> pd.DataFrame:
    results = []

    for playlist in tqdm(test_playlists, desc="Evaluating playlists"):
        track_uris = [t['track_uri'] for t in playlist['tracks']]

        # Hold-out evaluation setup
        num_holdout = min(20, max(1, int(len(track_uris) * 0.1)))
        seed_tracks = track_uris[:-num_holdout]
        held_out_tracks = track_uris[-num_holdout:]

        # Get recommendations using only track URIs
        recs = recommender.hybrid_recommend(track_uris=seed_tracks, top_k=20)

        # Calculate metrics
        hits = set(recs) & set(held_out_tracks)
        results.append({
            'pid': playlist['pid'],
            'precision': len(hits) / 20,
            'recall': len(hits) / len(held_out_tracks),
            'n_tracks': len(track_uris),
            'seed_size': len(seed_tracks),
            'known_tracks': len([t for t in seed_tracks if t in recommender.track_uri_to_index])
        })

    return pd.DataFrame(results)

# Load just the first 50 playlists from test data
test_path = base_path / 'Playlist Sample test' / 'mpd.slice.1000-1999.json'
with open(test_path, 'r') as f:
    test_playlists = json.load(f)['playlists'][:50]

"""# MAIN EXECUTION"""

def main():
    print("Loading models and data...")
    try:
        models = load_models()
        print("Models loaded successfully")
    except Exception as e:
        print(f"Failed to load models: {str(e)}")
        return

    print("Initializing recommender...")
    recommender = HybridRecommender(models=models)

    print("Loading test playlists...")
    test_path = base_path / 'Playlist Sample test' / 'mpd.slice.1000-1999.json'
    try:
        with open(test_path, 'r') as f:
            test_playlists = json.load(f)['playlists'][:50]
        print(f"Loaded {len(test_playlists)} test playlists")
    except Exception as e:
        print(f"Failed to load test playlists: {str(e)}")
        return

    print("\nEvaluating recommender...")
    results = evaluate_recommender(recommender, test_playlists)

    print("\nTop Results:")
    print(results.head(10))

    print("\nSummary Statistics:")
    print(f"Mean Precision@20: {results['precision'].mean():.3f}")
    print(f"Mean Recall: {results['recall'].mean():.3f}")

    print("\nSample Recommendation:")
    sample_tracks = [t['track_uri'] for t in test_playlists[0]['tracks'][:5]]
    print(f"Input Tracks: {sample_tracks[:3]}...")
    recs = recommender.hybrid_recommend(sample_tracks, top_k=5)
    print(f"Recommendations: {recs}")

if __name__ == "__main__":
    start_time = time.time()
    try:
        main()
    except Exception as e:
        print(f"Unexpected error: {str(e)}")
    finally:
        print(f"\nTotal execution time: {time.time()-start_time:.2f}s")