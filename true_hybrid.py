# -*- coding: utf-8 -*-
"""True Hybrid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tA2PMFr0d1XqXBB-1vNL6R5VI3IiyhVC

Imports
"""

import os
import numpy as np
import pandas as pd
import random
import pickle
from scipy.sparse import load_npz
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from keras import layers, ops
from keras.saving import register_keras_serializable

"""Connect Drive"""

#mount drive
from google.colab import drive
drive.mount('/content/drive')

"""# 1. Load Data and Mappings"""

def load_data(data_dir = '/content/drive/MyDrive/Graduation Project/Dev/'):
    """Load sparse matrix and mappings"""
    return {
        'sparse_matrix': load_npz(f'{data_dir}/playlist_track_sparse_matrix.npz'),
        'audio_features': pd.read_csv(f'{data_dir}/complete_audio_features.csv'),
        'track_uri_to_index': pickle.load(open(f'{data_dir}/track_uri_to_index.pkl', 'rb')),
        'track_index_to_uri': pickle.load(open(f'{data_dir}/track_index_to_uri.pkl', 'rb')),
        'playlist_id_to_index': pickle.load(open(f'{data_dir}/playlist_id_to_index.pkl', 'rb')),
        'playlist_index_to_id': pickle.load(open(f'{data_dir}/playlist_index_to_id.pkl', 'rb'))
    }

"""# 2. Data Preparation"""

def prepare_training_data(sparse_matrix, neg_samples=1):
    """Convert sparse matrix to training data with negative sampling"""
    coo = sparse_matrix.tocoo()
    positive_samples = list(zip(coo.row, coo.col, [1]*len(coo.row)))

    negative_samples = []
    positive_pairs = set(zip(coo.row, coo.col))
    all_tracks = range(sparse_matrix.shape[1])

    for p, _ in positive_pairs:
        for _ in range(neg_samples):
            t = random.choice(all_tracks)
            while (p, t) in positive_pairs:
                t = random.choice(all_tracks)
            negative_samples.append((p, t, 0))

    all_samples = positive_samples + negative_samples
    random.shuffle(all_samples)
    return pd.DataFrame(all_samples, columns=["playlist", "track", "value"])

"""# 3. Hybrid Model Architecture"""

@register_keras_serializable()
class BinaryF1Score(keras.metrics.Metric):
    def __init__(self, name='f1_score', threshold=0.5, **kwargs):
        super().__init__(name=name, **kwargs)
        self.threshold = threshold
        self.precision = keras.metrics.Precision(thresholds=threshold)
        self.recall = keras.metrics.Recall(thresholds=threshold)

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.cast(y_pred >= self.threshold, tf.float32)
        self.precision.update_state(y_true, y_pred, sample_weight)
        self.recall.update_state(y_true, y_pred, sample_weight)

    def result(self):
        p = self.precision.result()
        r = self.recall.result()
        return 2 * ((p * r) / (p + r + 1e-6))

    def reset_state(self):
        self.precision.reset_state()
        self.recall.reset_state()

@register_keras_serializable()
class HybridRecommender(keras.Model):
    def __init__(self, num_playlists, num_tracks, embedding_size=20, **kwargs):
        super().__init__(**kwargs)
        self.num_playlists = num_playlists
        self.num_tracks = num_tracks
        self.embedding_size = embedding_size

        # Embeddings with regularization
        self.pl_embed = layers.Embedding(
            num_playlists,
            embedding_size,
            embeddings_regularizer=keras.regularizers.l2(1e-4))
        self.tr_embed = layers.Embedding(
            num_tracks,
            embedding_size,
            embeddings_regularizer=keras.regularizers.l2(1e-4))

        # Feature processing
        self.feat_proj = keras.Sequential([
            layers.Dense(embedding_size, activation='relu',
                       kernel_regularizer=keras.regularizers.l1_l2(1e-5, 1e-4)),
            layers.LayerNormalization(),
            layers.Dense(embedding_size,
                       kernel_regularizer=keras.regularizers.l1_l2(1e-5, 1e-4))
        ])

        # Feature gating mechanism (missing in your original code)
        self.feat_gate = layers.Dense(embedding_size, activation='sigmoid',
                                    kernel_regularizer=keras.regularizers.l2(1e-4))

        # Feature combination
        self.combine = layers.Dense(embedding_size, activation='tanh',
                                  kernel_regularizer=keras.regularizers.l2(1e-4))

        # Regularization
        self.dropout = layers.Dropout(0.5)

    def call(self, inputs, training=None):
        pl_idx, tr_idx = inputs[:, 0], inputs[:, 1]

        # Get embeddings
        pl_emb = self.pl_embed(pl_idx)
        tr_emb = self.tr_embed(tr_idx)

        # Get and process features
        features = tf.gather(self.feature_matrix, tr_idx)
        if training:
            features = self.dropout(features)

        feat_proj = self.feat_proj(features)
        feat_proj = feat_proj * self.feat_gate(feat_proj)  # Now this will work
        tr_emb = self.combine(tr_emb + feat_proj)

        if training:
            pl_emb = self.dropout(pl_emb)
            tr_emb = self.dropout(tr_emb)

        logits = tf.reduce_sum(pl_emb * tr_emb, axis=1) / 0.2
        return ops.sigmoid(logits)

    def set_feature_matrix(self, feature_matrix):
        self.feature_matrix = feature_matrix

"""# 4. Model Training"""

def train_and_save_model(data_dir, model_save_path):
    """Complete training pipeline with model saving"""
    # Load data
    print("Loading data...")
    data = load_data(data_dir)

    # Prepare training data
    print("Preparing training data...")
    df = prepare_training_data(data['sparse_matrix'])
    x = df[["playlist", "track"]].values
    y = df["value"].values
    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1)

    # Get feature matrix
    print("Preparing feature matrix...")
    feature_cols = [
        'danceability', 'energy', 'key', 'loudness', 'mode',
        'speechiness', 'acousticness', 'instrumentalness',
        'liveness', 'valence', 'tempo', 'duration_ms'
    ]
    feature_matrix = data['audio_features'][feature_cols].values

    # Initialize and train model
    print("Initializing model...")
    model = HybridRecommender(
        data['sparse_matrix'].shape[0],
        data['sparse_matrix'].shape[1]
    )
    model.set_feature_matrix(feature_matrix)

    model.compile(
        optimizer=keras.optimizers.Adam(0.0005),  # Reduced learning rate
        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.2),  # Increased smoothing
        metrics=[
            keras.metrics.AUC(name='auc'),
            BinaryF1Score(threshold=0.5)  # Added F1 score
        ]
    )

    history = model.fit(
        x_train, y_train,
        batch_size=2048,  # Increased batch size
        epochs=30,  # Increased epochs since we're stopping early
        validation_data=(x_val, y_val),
        callbacks=[
            keras.callbacks.EarlyStopping(
                monitor='val_f1_score',  # Using F1 for early stopping
                patience=7,
                mode='max',
                restore_best_weights=True,
                min_delta=0.001
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,  # More aggressive reduction
                patience=3,
                min_lr=1e-6
            )
        ]
    )

    # Save the trained model
    print(f"Saving model to {model_save_path}...")
    model.save(model_save_path)
    print("Training complete and model saved!")

    return model, history

"""# 5. Main Execution"""

if __name__ == "__main__":
    # Configuration
    DATA_DIR = '/content/drive/MyDrive/Graduation Project/Dev'
    MODEL_SAVE_PATH = f'{DATA_DIR}/true_hybrid_recommender.keras'

    # Run training pipeline
    model, history = train_and_save_model(DATA_DIR, MODEL_SAVE_PATH)

"""# 6. Prediction Function"""

def load_recommender_model(model_path, data_dir):
    """Load model and necessary mappings for recommendations"""
    model = keras.models.load_model(model_path)
    data = load_data(data_dir)
    return model, data

def recommend_tracks(playlist_id, model, data, top_k=10):
    """Generate track recommendations for a playlist"""
    playlist_idx = data['playlist_id_to_index'][playlist_id]
    all_tracks = np.arange(len(data['track_index_to_uri']))
    pairs = np.array([[playlist_idx, t] for t in all_tracks])
    preds = model.predict(pairs).flatten()
    top_indices = np.argsort(preds)[-top_k:][::-1]
    return [data['track_index_to_uri'][i] for i in top_indices]

# Example usage:
# model, data = load_recommender_model(MODEL_SAVE_PATH, DATA_DIR)
# recommendations = recommend_tracks('your_playlist_id', model, data)