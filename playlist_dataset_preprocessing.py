# -*- coding: utf-8 -*-
"""Playlist Dataset Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GeOQU9ffvDd87ZS8824pCuEDTi0Zp8NX

Import libraries
"""

import os
import json
import pickle
import pandas as pd
from scipy.sparse import csr_matrix, save_npz

"""Step 1: mount Google Drive in Colab"""

from google.colab import drive
drive.mount('/content/drive')

"""Step 2: Set the Root Folder Path"""

root_folder = '/content/drive/MyDrive/Graduation Project/Playlists Sample Data'
output_folder = '/content/drive/MyDrive/Graduation Project/Dev'

"""Step 3: Initialize mappings and sparse matrix data"""

playlist_id_to_index = {}  # Maps playlist_id to row index
playlist_index_to_id = {}  # Maps row index to playlist_id
track_uri_to_index = {}    # Maps track_uri to column index
track_index_to_uri = {}     # Maps column index to track_uri

row_indices = []  # Row indices for non-zero values
col_indices = []  # Column indices for non-zero values
sparse_data = []  # Non-zero values (all 1s in this case)

"""Step 4: Process all JSON files"""

current_playlist_index = 0
current_track_index = 0

for subdir, _, files in os.walk(root_folder):
    for file in files:
        if file.endswith('.json'):
            file_path = os.path.join(subdir, file)

            with open(file_path, 'r') as f:
                json_data = json.load(f)

            for playlist in json_data.get('playlists', []):
                playlist_id = playlist.get('pid')

                # Update playlist mappings if new
                if playlist_id not in playlist_id_to_index:
                    playlist_id_to_index[playlist_id] = current_playlist_index
                    playlist_index_to_id[current_playlist_index] = playlist_id
                    current_playlist_index += 1

                row_idx = playlist_id_to_index[playlist_id]

                for track in playlist.get('tracks', []):
                    track_uri = track.get('track_uri')

                    # Update track mappings if new
                    if track_uri not in track_uri_to_index:
                        track_uri_to_index[track_uri] = current_track_index
                        track_index_to_uri[current_track_index] = track_uri
                        current_track_index += 1

                    col_idx = track_uri_to_index[track_uri]

                    # Add to sparse matrix data
                    row_indices.append(row_idx)
                    col_indices.append(col_idx)
                    sparse_data.append(1)

"""Step 5: Create and save sparse matrix"""

num_playlists = len(playlist_id_to_index)
num_tracks = len(track_uri_to_index)
sparse_matrix = csr_matrix((sparse_data, (row_indices, col_indices)),
                          shape=(num_playlists, num_tracks))

# Save the sparse matrix
matrix_path = os.path.join(output_folder, 'playlist_track_sparse_matrix.npz')
save_npz(matrix_path, sparse_matrix)

"""Step 6: Save all mappings"""

def save_mapping(mapping, filename):
    with open(os.path.join(output_folder, filename), 'wb') as f:
        pickle.dump(mapping, f)

save_mapping(track_uri_to_index, 'track_uri_to_index.pkl')
save_mapping(track_index_to_uri, 'track_index_to_uri.pkl')
save_mapping(playlist_id_to_index, 'playlist_id_to_index.pkl')
save_mapping(playlist_index_to_id, 'playlist_index_to_id.pkl')

print("Processing complete!")
print(f"Number of playlists: {num_playlists}")
print(f"Number of tracks: {num_tracks}")
print(f"Sparse matrix saved to: {matrix_path}")
print("All mapping files saved to:", output_folder)